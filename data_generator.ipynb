{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generates the Records_df and from that computes and exports Frequency_df\n",
    "### Frequency_df is the only one directly used by the Pathapp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"File to generate sample data for testing.\"\"\"\n",
    "from datetime import date, timedelta, datetime\n",
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sample_data import type_list,value_sign,day,adequacy_list,choices,last_week_date, last_month_date,results_list, genotype_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generates the numer of tests processed in a given date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### this function defines how busy each day of the week is\n",
    "def busy_days(n:int):\n",
    "    ans=100\n",
    "    if n==6:\n",
    "        ans=0\n",
    "    return ans\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### this function defines how busy each month is\n",
    "def busy_months(n:int):\n",
    "    ans=1\n",
    "    if n ==12:\n",
    "        ans= 0.8\n",
    "    if n in [1,2,6,7]:\n",
    "        ans=1.2\n",
    "    return ans    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_tests(fecha): ### This takes a date and returns how many tests occur\n",
    "    ans=int (busy_days(fecha.weekday())*busy_months(fecha.month)*np.random.uniform(0.95,1.05))\n",
    "    return ans\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a new row given a data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_row(fecha):############ This takesa a date and returns an entry in the Records_df\n",
    "    type_of_test=random.choices(type_list,weights=[3,4])[0]\n",
    "    adequacy=random.choices(adequacy_list,weights=[5,2,1])[0]\n",
    "    result=random.choices(results_list,weights=[4,1,1,1,1])[0]\n",
    "    gen_type=random.choice(genotype_list)\n",
    "    cytology=random.choices(value_sign,weights=[4,1])[0]+\"cytology\"\n",
    "    hystology=\"Not prescribed\"\n",
    "    if cytology==\"Positivecytology\":\n",
    "        hystology=random.choices(value_sign,weights=[92,8])[0]+\"hystology\"\n",
    "    need_surgery=0\n",
    "    if cytology==\"Negativecytology\":\n",
    "        need_surgery=random.choices([0,1],weights=[87,13])[0]\n",
    "    \n",
    "    new_row = pd.DataFrame([{'day':fecha.date(), 'type':type_of_test,'adequacy':adequacy, 'result':result,'genotype':gen_type,'cytology':cytology,'hystology':hystology,\"need_surgery\":need_surgery}])\n",
    "    return new_row"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose the date range "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_date = date.today() - timedelta(days = 366)\n",
    "ending_date=date.today() +timedelta(days = 20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Records_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_df():\n",
    "    columns=['day', 'type', 'adequacy', 'result', 'genotype', 'cytology', 'hystology']\n",
    "    records_df = pd.DataFrame(columns=columns)\n",
    "    daterange = pd.date_range(starting_date, ending_date, freq='D')\n",
    "    for item in daterange:\n",
    "        N_of_test=number_of_tests(item)\n",
    "        for patient in range(N_of_test):\n",
    "            new_row=make_row(item)\n",
    "            records_df = pd.concat([records_df, new_row], axis=0, ignore_index=True)\n",
    "    return records_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Records_df=generate_test_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34998, 8)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Records_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27975, 8)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Records_df[Records_df[\"cytology\"]==\"Positivecytology\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'float' and 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m Records_df[\u001b[39m\"\u001b[39;49m\u001b[39mneed_surgery\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49msum()\n",
      "File \u001b[0;32m/opt/miniconda3/envs/dash_tutorial/lib/python3.10/site-packages/pandas/core/generic.py:11797\u001b[0m, in \u001b[0;36mNDFrame._add_numeric_operations.<locals>.sum\u001b[0;34m(self, axis, skipna, level, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[1;32m  11777\u001b[0m \u001b[39m@doc\u001b[39m(\n\u001b[1;32m  11778\u001b[0m     _num_doc,\n\u001b[1;32m  11779\u001b[0m     desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mReturn the sum of the values over the requested axis.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11795\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m  11796\u001b[0m ):\n\u001b[0;32m> 11797\u001b[0m     \u001b[39mreturn\u001b[39;00m NDFrame\u001b[39m.\u001b[39;49msum(\n\u001b[1;32m  11798\u001b[0m         \u001b[39mself\u001b[39;49m, axis, skipna, level, numeric_only, min_count, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m  11799\u001b[0m     )\n",
      "File \u001b[0;32m/opt/miniconda3/envs/dash_tutorial/lib/python3.10/site-packages/pandas/core/generic.py:11501\u001b[0m, in \u001b[0;36mNDFrame.sum\u001b[0;34m(self, axis, skipna, level, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[1;32m  11492\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msum\u001b[39m(\n\u001b[1;32m  11493\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m  11494\u001b[0m     axis: Axis \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11499\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m  11500\u001b[0m ):\n\u001b[0;32m> 11501\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_min_count_stat_function(\n\u001b[1;32m  11502\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39msum\u001b[39;49m\u001b[39m\"\u001b[39;49m, nanops\u001b[39m.\u001b[39;49mnansum, axis, skipna, level, numeric_only, min_count, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m  11503\u001b[0m     )\n",
      "File \u001b[0;32m/opt/miniconda3/envs/dash_tutorial/lib/python3.10/site-packages/pandas/core/generic.py:11483\u001b[0m, in \u001b[0;36mNDFrame._min_count_stat_function\u001b[0;34m(self, name, func, axis, skipna, level, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[1;32m  11467\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m  11468\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUsing the level keyword in DataFrame and Series aggregations is \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m  11469\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdeprecated and will be removed in a future version. Use groupby \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11472\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m  11473\u001b[0m     )\n\u001b[1;32m  11474\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_agg_by_level(\n\u001b[1;32m  11475\u001b[0m         name,\n\u001b[1;32m  11476\u001b[0m         axis\u001b[39m=\u001b[39maxis,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11480\u001b[0m         numeric_only\u001b[39m=\u001b[39mnumeric_only,\n\u001b[1;32m  11481\u001b[0m     )\n\u001b[0;32m> 11483\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reduce(\n\u001b[1;32m  11484\u001b[0m     func,\n\u001b[1;32m  11485\u001b[0m     name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m  11486\u001b[0m     axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m  11487\u001b[0m     skipna\u001b[39m=\u001b[39;49mskipna,\n\u001b[1;32m  11488\u001b[0m     numeric_only\u001b[39m=\u001b[39;49mnumeric_only,\n\u001b[1;32m  11489\u001b[0m     min_count\u001b[39m=\u001b[39;49mmin_count,\n\u001b[1;32m  11490\u001b[0m )\n",
      "File \u001b[0;32m/opt/miniconda3/envs/dash_tutorial/lib/python3.10/site-packages/pandas/core/series.py:4816\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m   4812\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[1;32m   4813\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSeries.\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m does not implement \u001b[39m\u001b[39m{\u001b[39;00mkwd_name\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   4814\u001b[0m     )\n\u001b[1;32m   4815\u001b[0m \u001b[39mwith\u001b[39;00m np\u001b[39m.\u001b[39merrstate(\u001b[39mall\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 4816\u001b[0m     \u001b[39mreturn\u001b[39;00m op(delegate, skipna\u001b[39m=\u001b[39;49mskipna, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/dash_tutorial/lib/python3.10/site-packages/pandas/core/nanops.py:93\u001b[0m, in \u001b[0;36mdisallow.__call__.<locals>._f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     92\u001b[0m     \u001b[39mwith\u001b[39;00m np\u001b[39m.\u001b[39merrstate(invalid\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m---> 93\u001b[0m         \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     94\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     95\u001b[0m     \u001b[39m# we want to transform an object array\u001b[39;00m\n\u001b[1;32m     96\u001b[0m     \u001b[39m# ValueError message to the more typical TypeError\u001b[39;00m\n\u001b[1;32m     97\u001b[0m     \u001b[39m# e.g. this is normally a disallowed function on\u001b[39;00m\n\u001b[1;32m     98\u001b[0m     \u001b[39m# object arrays that contain strings\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[39mif\u001b[39;00m is_object_dtype(args[\u001b[39m0\u001b[39m]):\n",
      "File \u001b[0;32m/opt/miniconda3/envs/dash_tutorial/lib/python3.10/site-packages/pandas/core/nanops.py:418\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[0;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[39mif\u001b[39;00m datetimelike \u001b[39mand\u001b[39;00m mask \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    416\u001b[0m     mask \u001b[39m=\u001b[39m isna(values)\n\u001b[0;32m--> 418\u001b[0m result \u001b[39m=\u001b[39m func(values, axis\u001b[39m=\u001b[39;49maxis, skipna\u001b[39m=\u001b[39;49mskipna, mask\u001b[39m=\u001b[39;49mmask, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    420\u001b[0m \u001b[39mif\u001b[39;00m datetimelike:\n\u001b[1;32m    421\u001b[0m     result \u001b[39m=\u001b[39m _wrap_results(result, orig_values\u001b[39m.\u001b[39mdtype, fill_value\u001b[39m=\u001b[39miNaT)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/dash_tutorial/lib/python3.10/site-packages/pandas/core/nanops.py:491\u001b[0m, in \u001b[0;36mmaybe_operate_rowwise.<locals>.newfunc\u001b[0;34m(values, axis, **kwargs)\u001b[0m\n\u001b[1;32m    488\u001b[0m         results \u001b[39m=\u001b[39m [func(x, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m arrs]\n\u001b[1;32m    489\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray(results)\n\u001b[0;32m--> 491\u001b[0m \u001b[39mreturn\u001b[39;00m func(values, axis\u001b[39m=\u001b[39;49maxis, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/dash_tutorial/lib/python3.10/site-packages/pandas/core/nanops.py:631\u001b[0m, in \u001b[0;36mnansum\u001b[0;34m(values, axis, skipna, min_count, mask)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[39melif\u001b[39;00m is_timedelta64_dtype(dtype):\n\u001b[1;32m    629\u001b[0m     dtype_sum \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdtype(np\u001b[39m.\u001b[39mfloat64)\n\u001b[0;32m--> 631\u001b[0m the_sum \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39;49msum(axis, dtype\u001b[39m=\u001b[39;49mdtype_sum)\n\u001b[1;32m    632\u001b[0m the_sum \u001b[39m=\u001b[39m _maybe_null_out(the_sum, axis, mask, values\u001b[39m.\u001b[39mshape, min_count\u001b[39m=\u001b[39mmin_count)\n\u001b[1;32m    634\u001b[0m \u001b[39mreturn\u001b[39;00m the_sum\n",
      "File \u001b[0;32m/opt/miniconda3/envs/dash_tutorial/lib/python3.10/site-packages/numpy/core/_methods.py:48\u001b[0m, in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_sum\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     47\u001b[0m          initial\u001b[39m=\u001b[39m_NoValue, where\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m---> 48\u001b[0m     \u001b[39mreturn\u001b[39;00m umr_sum(a, axis, dtype, out, keepdims, initial, where)\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'float' and 'list'"
     ]
    }
   ],
   "source": [
    "Records_df[\"need_surgery\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27975, 8)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Records_df[Records_df[\"need_surgery\"]==0].shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is the dataframe that the app takes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Records_df.to_csv(\"NewRecords.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GENERATE FREQUENCY DATA FRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_row_frequency(df,fecha):\n",
    "    columnas= list(Records_df.columns)[1:]\n",
    "    new_row_in={\"day\":fecha}\n",
    "    df_fecha=df[df[\"day\"]==fecha]\n",
    "    new_row_in[\"All\"]=df_fecha.shape[0]\n",
    "    for columna in columnas:\n",
    "        column_values=list(df_fecha[columna].unique())\n",
    "        for tipo in column_values:\n",
    "            temp_df=df_fecha[df_fecha[columna]==tipo]\n",
    "            new_row_in[tipo]=temp_df.shape[0]\n",
    "    types=list(df_fecha[\"type\"].unique())\n",
    "    adequacies=list(df_fecha[\"adequacy\"].unique())\n",
    "    cytologies=list(df_fecha[\"cytology\"].unique())\n",
    "    hystologies=list(df_fecha[\"hystology\"].unique())\n",
    "    for tipo in types:\n",
    "        for ad in adequacies:\n",
    "            temp_df=df_fecha[(df_fecha[\"type\"]==tipo) & (df_fecha[\"adequacy\"]==ad)]\n",
    "            new_row_in[tipo+ad]=temp_df.shape[0]\n",
    "        for cyt in cytologies:\n",
    "            temp_df=df_fecha[(df_fecha[\"type\"]==tipo) & (df_fecha[\"cytology\"]==cyt)]\n",
    "            new_row_in[tipo+cyt]=temp_df.shape[0]\n",
    "        for hyst in hystologies:\n",
    "            temp_df=df_fecha[(df_fecha[\"type\"]==tipo) & (df_fecha[\"hystology\"]==hyst)]\n",
    "            new_row_in[tipo+hyst]=temp_df.shape[0]\n",
    "\n",
    "\n",
    "        # new_row_in[\"weekday\"]=week_day(fecha.weekday())\n",
    "    \n",
    "    return pd.DataFrame([new_row_in])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_frequency_df(df):\n",
    "    fechas=df[\"day\"].unique()\n",
    "    freq_df=pd.DataFrame()\n",
    "    for fecha in fechas:\n",
    "        freq_df=pd.concat([freq_df,new_row_frequency(df,fecha)],axis=0, ignore_index=True)\n",
    "    \n",
    "    return freq_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Frequency_df=make_frequency_df(Records_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Frequency_df.to_csv('Frequency.csv')#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dash_tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31fb68429e91cc16ee00ba7a208e84b76758121316b8f5a99b7f17a1b208923b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
